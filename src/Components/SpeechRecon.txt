import { useEffect, useState } from 'react';
import * as TF from '@tensorflow/tfjs';
import * as Speech from '@tensorflow-models/speech-commands';

function VoiceRecon() {
    const [model,setModel] = useState(null);
    const [action,setAction] = useState(null);
    const [labels,setLabels] = useState(null);

    const loadModel = async() => {
        const recognizer = await speech.create('BROWSER_FFT');
        console.log('Model Loaded');

        await recognizer.ensureModelLoaded()
        console.log(recognizer.wordLabels());
        setModel(recognizer);
        setLabels(recognizer.wordLabels());
    }

    useEffect(()=>{loadModel()}, []);

    const argMax =(arr)=>{
        return arr.map((x,i)=>[x,i]).reduce((r,a)=>(a[0]>r[0] ? a : r)[1]);
    }

    const recognizeCommands = async() => {
        console.log('Listening for commands');
        model.listen(result=>{
            console.log(result)
            setAction(labels[argMax(Object.values(result.scores))])
        }, {includeSpectrogram:true, probabilityThreshold:0.9})
        setTimeout(()=>model.stopListening(), 10e3)
    }

    return(
        <div>
            <button onClick={recognizeCommands}>Command</button>
            {action ? <div>{action}</div> : <div>No Action Detected</div> }
        </div>
    )
}